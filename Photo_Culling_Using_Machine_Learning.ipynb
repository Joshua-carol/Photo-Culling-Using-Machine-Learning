{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "4TPQQfTKG3qP",
        "outputId": "b9e73bd8-38df-4029-aa84-12ac2f27de22"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-49b0ea1f4f73>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive and import necessary libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.ndimage import variance\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBvhbkabHazI"
      },
      "outputs": [],
      "source": [
        "# Feature extraction functions\n",
        "def calculate_exposure_score(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
        "    hist_norm = hist.ravel() / hist.sum()\n",
        "    exposure_score = -np.sum(hist_norm * np.log2(hist_norm + 1e-7))\n",
        "    return exposure_score\n",
        "\n",
        "def calculate_focus_score(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    return laplacian_var\n",
        "\n",
        "def calculate_composition_score(image):\n",
        "    h, w, _ = image.shape\n",
        "    central_region = image[int(h*0.3):int(h*0.7), int(w*0.3):int(w*0.7)]\n",
        "    central_brightness = np.mean(cv2.cvtColor(central_region, cv2.COLOR_BGR2GRAY))\n",
        "    overall_brightness = np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
        "    composition_score = 1 - abs(central_brightness - overall_brightness) / overall_brightness\n",
        "    return composition_score\n",
        "\n",
        "def calculate_clarity_score(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
        "    sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n",
        "    clarity_score = np.mean(sobel_combined)\n",
        "    return clarity_score\n",
        "\n",
        "def calculate_detail_score(image):\n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_channel = lab_image[:, :, 0]\n",
        "    detail_score = variance(l_channel)\n",
        "    return detail_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwmIcsJlHyxN"
      },
      "outputs": [],
      "source": [
        "# Function to extract features from an image\n",
        "def extract_features(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    exposure = calculate_exposure_score(image)\n",
        "    focus = calculate_focus_score(image)\n",
        "    composition = calculate_composition_score(image)\n",
        "    clarity = calculate_clarity_score(image)\n",
        "    detail = calculate_detail_score(image)\n",
        "    return [exposure, focus, composition, clarity, detail]\n",
        "\n",
        "# Function to load data by traversing all directories and subdirectories\n",
        "def load_data_from_folders(main_folder_path):\n",
        "    data = []\n",
        "    folder_check = {'Good': 0, 'Bad': 0, 'Decent': 0}  # Sentence case labels\n",
        "\n",
        "    # Walk through the main folder and its subfolders\n",
        "    for root, dirs, files in os.walk(main_folder_path):\n",
        "        if 'Good' in root:\n",
        "            label = 'Good'\n",
        "            folder_check['Good'] += 1\n",
        "        elif 'Bad' in root:\n",
        "            label = 'Bad'\n",
        "            folder_check['Bad'] += 1\n",
        "        elif 'Decent' in root:\n",
        "            label = 'Decent'\n",
        "            folder_check['Decent'] += 1\n",
        "        else:\n",
        "            continue  # Skip any folder that isn't Good, Bad, or Decent\n",
        "\n",
        "        # Extract features from all images in this folder\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                features = extract_features(image_path)\n",
        "                features.append(label)  # Append the label (\"Good\", \"Bad\", or \"Decent\")\n",
        "                data.append(features)\n",
        "\n",
        "    # Check if all folders (Good, Bad, Decent) were found in the structure\n",
        "    for folder, count in folder_check.items():\n",
        "        if count == 0:\n",
        "            print(f\"Warning: No {folder} folder found in the dataset.\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Path to the main folder\n",
        "main_folder_path = '/content/drive/My Drive/Photo Culling Using Machine Learning Dataset'\n",
        "\n",
        "# Load data by traversing all subdirectories\n",
        "all_data = load_data_from_folders(main_folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugx9zIqmJgDU"
      },
      "outputs": [],
      "source": [
        "# If no images are found, raise an error\n",
        "if len(all_data) == 0:\n",
        "    raise ValueError(\"No images were found. Please check your folder paths and ensure that the images are correctly placed.\")\n",
        "\n",
        "# Create a DataFrame\n",
        "columns = ['Exposure', 'Focus', 'Composition', 'Clarity', 'Detail', 'Label']\n",
        "df = pd.DataFrame(all_data, columns=columns)\n",
        "\n",
        "# Print the number of images in each category for debugging\n",
        "print(f\"Number of images in each category:\\n{df['Label'].value_counts()}\")\n",
        "\n",
        "# Step 2: Prepare features (X) and labels (y)\n",
        "X = df[['Exposure', 'Focus', 'Composition', 'Clarity', 'Detail']]\n",
        "y = df['Label']\n",
        "\n",
        "# Print the shape of the dataset for further debugging\n",
        "print(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")\n",
        "\n",
        "# Step 3: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIQLx2k8Jq2M"
      },
      "outputs": [],
      "source": [
        "# Step 4: Train a Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Test the model\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Output the results\n",
        "print(\"Initial Accuracy:\", accuracy)\n",
        "print(\"Initial Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 7: Save the classification report to a file\n",
        "report_path = '/content/drive/My Drive/classification_report.txt'\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(f\"Accuracy: {accuracy}\\n\")\n",
        "    f.write(\"Classification Report:\\n\")\n",
        "    f.write(classification_rep)\n",
        "\n",
        "print(f\"Initial classification report saved to {report_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9NPmdB0J2Yj"
      },
      "outputs": [],
      "source": [
        "# Cross-validation to assess model performance\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print(f\"Cross-validation scores: {scores}\")\n",
        "print(f\"Mean cross-validation accuracy: {scores.mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ5kEcL9J_1a"
      },
      "outputs": [],
      "source": [
        "# Step 8: Misclassification Feedback Loop (Retraining with Export)\n",
        "def feedback_loop_with_export(X_test, y_test, y_pred, X_train, y_train, clf, iterations=10):\n",
        "    \"\"\"\n",
        "    Feedback loop to retrain on misclassified examples.\n",
        "    Adds misclassified examples back into the training set and retrains the model.\n",
        "    Exports the classification results to an Excel file after each iteration.\n",
        "    \"\"\"\n",
        "    for i in range(iterations):\n",
        "        # Identify misclassified examples\n",
        "        misclassified_indices = [i for i in range(len(y_test)) if y_test.iloc[i] != y_pred[i]]\n",
        "\n",
        "        if not misclassified_indices:\n",
        "            print(\"No more misclassifications. Training complete.\")\n",
        "            break\n",
        "\n",
        "        print(f\"Iteration {i+1}: {len(misclassified_indices)} misclassified examples found.\")\n",
        "\n",
        "        # Add misclassified examples back into the training set\n",
        "        X_misclassified = X_test.iloc[misclassified_indices]\n",
        "        y_misclassified = y_test.iloc[misclassified_indices]\n",
        "\n",
        "        # Ensure that n_samples is at least 1\n",
        "        n_samples_to_add = max(1, int(0.5 * len(X_misclassified)))\n",
        "\n",
        "        # Sample misclassified examples to prevent overfitting\n",
        "        X_misclassified_sample, y_misclassified_sample = resample(X_misclassified, y_misclassified, replace=False, n_samples=n_samples_to_add)\n",
        "\n",
        "        X_train = pd.concat([X_train, X_misclassified_sample])\n",
        "        y_train = pd.concat([y_train, y_misclassified_sample])\n",
        "\n",
        "        # Retrain the model on the updated training set\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Test the model again\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Recalculate accuracy and classification report\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "        print(f\"Iteration {i+1} Accuracy: {accuracy}\")\n",
        "        print(f\"Iteration {i+1} Classification Report:\\n\", classification_rep)\n",
        "\n",
        "        # Save each iteration's classification report as an Excel file\n",
        "        results_df = X_test.copy()  # Copy X_test to retain the feature information\n",
        "        results_df['True Label'] = y_test.values  # Add true labels\n",
        "        results_df['Predicted Label'] = y_pred  # Add predicted labels\n",
        "\n",
        "        # Export the classification results to an Excel file\n",
        "        excel_output_path = f'/content/drive/My Drive/image_classification_results_iteration_{i+1}.xlsx'\n",
        "        results_df.to_excel(excel_output_path, index=False)\n",
        "\n",
        "        print(f\"Iteration {i+1} classification results saved to {excel_output_path}\")\n",
        "\n",
        "# Run the feedback loop for 10 iterations\n",
        "feedback_loop_with_export(X_test, y_test, y_pred, X_train, y_train, clf)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}